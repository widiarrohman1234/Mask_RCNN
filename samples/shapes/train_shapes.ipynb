{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start with me :)\n",
      "Requirement already satisfied: opencv-python in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: keras in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: scipy in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scipy) (1.23.5)\n",
      "Requirement already satisfied: scikit-image in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (0.16.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scikit-image) (3.7.5)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from imageio>=2.3.0->scikit-image) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.17.0)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (2.13.1)\n",
      "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: absl-py>=1.0.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (1.70.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (3.11.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (4.25.8)\n",
      "Requirement already satisfied: setuptools in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorflow[and-cuda]) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/irium/miniconda3/envs/mask_rcnnaktwelve3.8/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow[and-cuda]) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's start with me :)\")\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install keras\n",
    "!pip install scipy\n",
    "!pip install scikit-image\n",
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 10 01:39:53 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060        On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   55C    P8             18W /  170W |    1205MiB /  12288MiB |     33%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A              17      G   /Xwayland                             N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 01:39:57.703556: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-10 01:39:58.044947: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-10 01:39:58.049205: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-10 01:39:59.901807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n",
      "[]\n",
      "2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 01:40:02.605302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-10 01:40:04.071611: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; \n",
    "import keras; \n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "# COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "COCO_MODEL_PATH = os.path.abspath(\"/home/irium/htdocs/Mask_RCNNakTwelve/Mask_RCNN/mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19162/498919690.py:66: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return mask.astype(np.bool), class_ids.astype(np.int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 01:40:38.762486: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2025-08-10 01:40:38.869084: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'proposal_targets/cond/output/_16'\n",
      "2025-08-10 01:40:39.793667: W tensorflow/c/c_api.cc:304] Operation '{name:'bn4v_branch2b/moving_mean/Assign' id:4669 op device:{requested: '', assigned: ''} def:{{{node bn4v_branch2b/moving_mean/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](bn4v_branch2b/moving_mean, bn4v_branch2b/moving_mean/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-08-10 01:40:42.644358: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-08-10 01:40:42.942503: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-08-10 01:40:45.901018: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-08-10 01:40:48.373707: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-08-10 01:40:48.517684: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.checkpoint_path = os.path.join(model.log_dir, \"mask_rcnn_{epoch:04d}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/irium/htdocs/Mask_RCNNakTwelve/Mask_RCNN/logs/shapes20250810T0143/mask_rcnn_{epoch:04d}.weights.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras' has no attribute 'ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the head branches\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Passing layers=\"heads\" freezes all layers except the head\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# layers. You can also pass a regular expression to select\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# which layers to train by name pattern.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheads\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/htdocs/Mask_RCNNakTwelve/Mask_RCNN/mrcnn/model.py:2644\u001b[0m, in \u001b[0;36mMaskRCNN.train\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2642\u001b[0m log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint Path: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_path))\n\u001b[1;32m   2643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_trainable(layers)\n\u001b[0;32m-> 2644\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_MOMENTUM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;66;03m# Work-around for Windows: Keras fails on Windows when using\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;66;03m# multiprocessing workers. See discussion here:\u001b[39;00m\n\u001b[1;32m   2648\u001b[0m \u001b[38;5;66;03m# https://github.com/matterport/Mask_RCNN/issues/13#issuecomment-353124009\u001b[39;00m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/htdocs/Mask_RCNNakTwelve/Mask_RCNN/mrcnn/model.py:2434\u001b[0m, in \u001b[0;36mMaskRCNN.compile\u001b[0;34m(self, learning_rate, momentum)\u001b[0m\n\u001b[1;32m   2429\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;66;03m# old\u001b[39;00m\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;66;03m# loss = (\u001b[39;00m\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;66;03m#     tf.reduce_mean(input_tensor=layer.output, keepdims=True)\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \u001b[38;5;66;03m#     * self.config.LOSS_WEIGHTS.get(name, 1.))\u001b[39;00m\n\u001b[0;32m-> 2434\u001b[0m loss \u001b[38;5;241m=\u001b[39m (\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241m.\u001b[39mmean(layer\u001b[38;5;241m.\u001b[39moutput, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mLOSS_WEIGHTS\u001b[38;5;241m.\u001b[39mget(name, \u001b[38;5;241m1.\u001b[39m))\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# old\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;66;03m# self.keras_model.add_loss(loss)\u001b[39;00m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;66;03m# saved\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'ops'"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=10, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask_rcnnaktwelve3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
